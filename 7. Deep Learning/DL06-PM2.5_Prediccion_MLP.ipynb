{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[],"collapsed_sections":["4q0yLr81suuJ"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"7qukWkWesutH"},"source":["# Deep Learning\n","# DL06 PM2.5 Prediccion MLP-SOLUCION"]},{"cell_type":"markdown","metadata":{"id":"WbVBuTMVCPha"},"source":["## <font color='blue'>**Multilayer preceptron aplicado a series de tiempo univariadas**</font>\n","\n","\n","Una serie de tiempo es una serie de puntos de datos indexados (o listados o graficados) en orden de tiempo. Más comúnmente, una serie de tiempo es una secuencia tomada en sucesivos puntos equidistantes en el tiempo. Por lo tanto, es una secuencia de datos de tiempo discreto. Ejemplos de series temporales son las alturas de las mareas oceánicas, los recuentos de manchas solares y el valor de cierre diario del Promedio Industrial Dow Jones.\n","\n","Las series temporales se trazan con mucha frecuencia a través de gráficos de líneas. Las series de tiempo se usan en estadística, procesamiento de señales, reconocimiento de patrones, econometría, finanzas matemáticas, pronóstico del tiempo, predicción de terremotos, electroencefalografía, ingeniería de control, astronomía, ingeniería de comunicaciones y en gran medida en cualquier dominio de la ciencia aplicada y la ingeniería que involucra mediciones temporales.\n","\n","El término __serie temporal univariadas__, se refiere a una serie temporal que consiste en observaciones individuales (escalares) registradas secuencialmente en incrementos de tiempo iguales.\n","    \n","En este notebook, utilizaremos un perceptrón multicapa para desarrollar modelos de pronóstico de series temporales univariadas.\n","El conjunto de datos utilizado para los ejemplos de este notebook es sobre la contaminación del aire medida por la concentración de material particulado (PM) de diámetro menor o igual a 2.5 micrómetros. Hay otras variables\n","tales como presión de aire, temperatura del aire, punto de rocío, que tambien serán utilizadas para realizar predicciones.\n","\n","\n","En este caso, se desarrollará un modelo de series temporales: para la predicción de pm2.5.\n","\n","El notebook se divide en las siguientes etapas:\n","1. Visualización de la data\n","2. Procesamiento de la data\n","3. Construcción del modelo y su entrenamiento con Keras\n","4. Resultados y validación del modelo.\n","\n","\n","Importancia de la predicción del material particulado:\n","\n","El material particulado respirable presente en la atmósfera de nuestras ciudades en forma sólida o líquida (polvo, cenizas, hollín, partículas metálicas, cemento y polen, entre otras) se puede dividir, según su tamaño, en dos grupos principales. A las de diámetro aerodinámico igual o inferior a los 10 µm o 10 micrómetros (1 $\\mu m$ corresponde a la milésima parte de un milímetro) se las denomina PM10 y a la fracción respirable más pequeña, PM2,5. Estas últimas están constituidas por aquellas partículas de diámetro aerodinámico inferior o igual a los 2,5 micrómetros, es decir, son 100 veces más delgadas que un cabello humano.\n","\n","\n","El conjunto de datos se ha descargado del repositorio de aprendizaje automático de UCI.\n","\n","https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data"]},{"cell_type":"code","metadata":{"id":"7YxHla3f9LgN"},"source":["#Montar Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGKzg0SYsutI"},"source":["### Etapa 1. Visualización de la data\n","\n","En esta etapa nos hacemos una idea de como es la distribución de la data. Entre que valores fluctua,  en el caso de las series de tiempo univariadas, es natural realizar Boxplots y graficos de tiempo. Las librerías tipicas que utilizaremos en esta etapa son: `pandas`, `matplotlib`, `numpy` y `seaborn`.\n"]},{"cell_type":"code","metadata":{"id":"BEns_pXQsutJ"},"source":["from __future__ import print_function\n","import os\n","import sys\n","import pandas as pd\n","import numpy as np\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUc4_exIsutO"},"source":["#set current working directory\n","path = '/content/drive/MyDrive/Curso/Industria Inteligente/2023-2S/Datos/'\n","os.chdir(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbmgFG7tsutQ"},"source":["#Read the dataset into a pandas.DataFrame\n","df = pd.read_csv('PRSA_data_2010.1.1-2014.12.31.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVwqyjw7Gt1u"},"source":["#Cargar archivo subido\n","df = pd.read_csv('PRSA_data_2010.1.1-2014.12.31.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g1b6ooXLFq4N"},"source":["## <font color='green'>**Actividad 1**</font>\n","\n","En esta actividad queremos visualizar nuestra data.  (30 minutos)\n","\n","1. ¿Cuantos valores nulos tenemos?, como los podemos tratar. ¿Probemos borrando data?\n","\n","2. Cree una columna que se llame datetime y ordenelo en forma ascendente. Puede mirar el siguiente código para inspirarse.\n","\n","```python\n","df['datetime'] = df[['year', 'month', 'day', 'hour']].apply(lambda row: datetime.datetime(year=row['year'], month=row['month'], day=row['day'],\n","                                                                                          hour=row['hour']), axis=1)\n","df.sort_values('datetime', ascending=True, inplace=True)\n","```\n","\n","3. Visualice la serie de tiempo para la variable pm2.5. Utilice gráficos de línea, box plots e histogramas. Visualice distintos periodos de tiempo, se observa el tamaño del ciclo?\n","\n"]},{"cell_type":"code","metadata":{"id":"Jao1PoFSsutT"},"source":["print('Shape of the dataframe:', df.shape)\n","print(df['pm2.5'].isna().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8C_jZWfusutW"},"source":["#Veamos las primeras 5 líneas del dataframe\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xMkNXnzWsutZ"},"source":["### Datos faltantes:\n","\n","En los datos de series de tiempo, si faltan valores, hay dos formas de tratar los datos incompletos:\n","\n","1. Omita todo el registro que contiene información.\n","2. Imputar la información que falta.\n","\n","Dado que los datos de series temporales tienen propiedades temporales, solo algunas de las metodologías estadísticas son apropiadas para los datos de series temporales.\n","\n","Metodos elementales de imputación:\n","1. Con la media\n","2. Con la mediana\n","3. Con la moda\n","4. Calcular el valor apropiado y reeemplazar los NAs\n","5. Usar modelos estadísticos y de Machine Leaning (e.g. K-NN)."]},{"cell_type":"markdown","metadata":{"id":"TWQQaKw3GK0h"},"source":["<font color='green'>**Fin Actividad 1**</font>"]},{"cell_type":"markdown","metadata":{"id":"e_7NuGZbsutm"},"source":["### Etapa 2. Preprocesamiento de la data\n","\n","En esta segunda etapa preparamos los datos con el objetivo de realizar un entrenamiento robusto de nuestra red neuronal. Usualmente los datos como primera etapa se normalizan. Empiricamente se ha observando que los datos normalizados (No siempre) generan modelos de clasificiación y de regresión con mejores metricas que los no normalizadas. Por otra parte, Los algoritmos de descenso de gradiente funcionan mejor (por ejemplo, convergen más rápido) si las variables están dentro del rango $[-1, 1]$. Muchas fuentes relajan el límite incluso $[-3, 3]$.\n","\n","Posteriormente los datos debens ser separados en tres conjuntos: Entrenamiento, validación y test. Usualmente el ultimo de test se utiliza con una prueba nueva de datos. Finalmente debemos construir el conjunto de vectores que serán utilizados para entrenar la red neuronal perceptron multicapa. Las librerias. Adicionalmente en esta sección utilizaremos la librería `sklearn` para realizar la normalización.\n"]},{"cell_type":"code","metadata":{"id":"LTNpkzXNsutm"},"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","df['scaled_pm2.5'] = scaler.fit_transform(np.array(df['pm2.5']).reshape(-1, 1)) # Nos lo deja como vector."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRKIWfREsuto"},"source":["import joblib\n","\n","# Guardemos el escalador\n","fileoutScaler = 'scaler_model.sav'\n","joblib.dump(scaler, fileoutScaler)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"fDkSXwc_sutr"},"source":["<p style='text-align: justify;'>\n","Antes de entrenar el modelo, el conjunto de datos se divide en dos partes: conjunto de entrenamiento y conjunto de validación.\n","La red neuronal se entrena en el conjunto de entrenamiento. Esto significa el cálculo de la función de pérdida, backpropagation\n","y los pesos actualizados por un algoritmo de descenso de gradiente se realizan en el conjunto de entrenamiento. El conjunto de validación se utiliza para evaluar el modelo y para determinar el número de epochs en el entrenamiento del modelo. Aumentando el número de epochs disminuirán aún más la función de pérdida en el conjunto de entrenamiento, pero es posible que no necesariamente tengan el mismo efecto para el conjunto de validación debido al sobreajuste en el conjunto de entrenamiento. Utilizamos Keras con el backend Tensorflow para definir y entrenar el modelo. Todos los pasos involucrados en la capacitación y validación del modelo se realizan llamando a las funciones apropiadas de la API de Keras.\n"," </p>"]},{"cell_type":"code","metadata":{"id":"kEt4lo1Asutr"},"source":["\"\"\"\n","Comencemos dividiendo el conjunto de datos en entrenamiento y validación. El período de tiempo del conjunto de datos si es de\n","1 de enero de 2010 al 31 de diciembre de 2014. Los primeros cuatro años: 2010 a 2013 se utiliza como entrenamiento y\n","2014 se mantiene para validación.\n","\"\"\"\n","# Utilizamos pandas para realizar este proceso.\n","split_date = datetime.datetime(year=2014, month=1, day=1, hour=0)\n","df_train = df.loc[df['datetime'] < split_date]\n","df_val = df.loc[df['datetime'] >= split_date]\n","print('Shape of train:', df_train.shape)\n","print('Shape of test:', df_val.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQbTeH7Lsutt"},"source":["#Miremos nuestro conjunto de entrenamiento\n","df_train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B00t-raZsutv"},"source":["#Miremos nuestro conjunto de validación\n","df_val.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMJQVpp9sutx"},"source":["#Vamos a resetar los indices para ser ordenados\n","df_val.reset_index(drop=True, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RODEcVL9sut0"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Asumiendo que 'df', 'df_train' y 'df_val' son tus DataFrames y tienen las columnas necesarias\n","\n","\"\"\"\n","El conjunto de entrenamiento y validación lo volvemos a dibujar.\n","\"\"\"\n","\n","plt.figure(figsize=(16, 5.5))\n","g = sns.lineplot(x=df['datetime'], y=df_train['scaled_pm2.5'], color='b')\n","g.set_title('Serie de tiempo del conjunto de entrenamiento pm2.5 escalada')\n","g.set_xlabel('Index')\n","g.set_ylabel('Valores escalados de pm2.5')\n","\n","plt.figure(figsize=(16, 5.5))\n","g = sns.lineplot(x=df['datetime'], y=df_val['scaled_pm2.5'], color='r')\n","g.set_title('Serie de tiempo del conjunto de validación pm2.5 escalada')\n","g.set_xlabel('Index')\n","g.set_ylabel('Valores escalados de pm2.5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yIfcBVyLsut2"},"source":["\n","Ahora necesitamos generar vectores ($X$) y una variable objetivo ($y$) para entrenar y validar. La matriz de los regresores o variables independientes y la matriz  de la variable dependiente se crean a partir de la matriz 1-D original de la columna `scaled_pm2.5`. Para el modelo de pronóstico de series de tiempo, los últimos siete días de observaciones se utilizan para predecir el día siguiente, este valor se estudia y se pueden ejercitar distintas ventanas de tiempo. el dia 7 surge de la observación de los gráficos de linea.  Definimos una función que toma la serie de tiempo original y el número de pasos de tiempo en los regresores como entrada para generar las matrices de $X$ e $y$."]},{"cell_type":"code","metadata":{"id":"U568hfKrsut2"},"source":["def makeXy(ts, nb_timesteps):\n","    \"\"\"\n","    Input:\n","           ts: serie de tiempo original.\n","           nb_timesteps: Ventana de tiempo.\n","    Output:\n","           X: 2-D array de los regresores o variables independientes.\n","           y: 1-D array de variable dependiente.\n","    \"\"\"\n","    X = []\n","    y = []\n","    for i in range(nb_timesteps, ts.shape[0]):\n","        X.append(list(ts.loc[i-nb_timesteps:i-1]))\n","        y.append(ts.loc[i])\n","    X, y = np.array(X), np.array(y) # Lo tranformamos a nparray\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9HYzjx2sut4"},"source":["X_train, y_train = makeXy(df_train['scaled_pm2.5'], 7)\n","print('Shape of train arrays:', X_train.shape, y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"08UoFgp-sut6"},"source":["X_val, y_val = makeXy(df_val['scaled_pm2.5'], 7)\n","print('Shape of validation arrays:', X_val.shape, y_val.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z-RTNMVJsut7"},"source":["### Etapa 3. Definiendo el modelo de perceptron de multicapa en Keras\n","<p style='text-align: justify;'>\n","Un solo perceptrón solo se puede utilizar para implementar funciones separables linealmente. Toma entradas reales y booleanas y les asocia un conjunto de pesos, junto con un sesgo (el umbral que mencioné anteriormente). Aprendemos los pesos, obtenemos la función. Usemos un perceptrón para aprender una función OR. </p>\n","\n","![Perceptron](https://drive.google.com/uc?export=view&id=1Kp8OYWpZbPX3PNkbsw154Q8KOqbdicuf)\n","\n","\n","\n","![Perceptron Matematica](https://drive.google.com/uc?export=view&id=1_RhrJBSBSsjbpc89XGrX32VDec7WmLXA)\n","\n","\n","<p style='text-align: justify;'>\n","Como su nombre indica, el MLP es esencialmente una combinación de capas de perceptrones entrelazados. Utiliza las salidas de la primera capa como entradas de la siguiente capa hasta que finalmente, después de un número particular de capas, alcanza la capa de salida. Las capas entre las capas de entrada y salida se denominan capas ocultas. Al igual que con el perceptrón, MLP también tiene pesos que se deben ajustar para entrenar el sistema. Estos pesos ahora vienen en forma de matriz en cada unión entre capas. </p>\n","\n","\n","\n","![MLP](https://drive.google.com/uc?export=view&id=15L2S9jFGi_j7E2KNK2p6Gno1_xKZbeQP)\n","\n","\n","<p style='text-align: justify;'>\n","La primera parte de la creación de un MLP es definir una topología y desarrollar el algoritmo feedforward. Feedforward es esencialmente el proceso utilizado para convertir la entrada en una salida. Sin embargo, no es tan simple como en el perceptrón, ya que ahora necesita iterar sobre varias capas. Usando operaciones matriciales</p>"]},{"cell_type":"markdown","metadata":{"id":"W6P0ln8Psut8"},"source":["Ahora definimos el MLP usando el framework de redes neuronales `Keras`. En este enfoque, una capa se puede declarar como la entrada de la siguiente capa al momento de definir la siguiente capa."]},{"cell_type":"code","metadata":{"id":"B04Cze_Esut8"},"source":["from keras.layers import Dense, Input, Dropout\n","from keras.optimizers import SGD\n","from keras.models import Model\n","from keras.models import load_model\n","from keras.callbacks import ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VweptLGEsut-"},"source":["# Defina la capa de entrada que tiene forma (, 7) y de tipo float32. Ninguno indica el número de instancias\n","input_layer = Input(shape=(7,), dtype='float32')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DQL5JmPGsuuB"},"source":["#### Funciones de activación\n","\n","La función de activación no es más que una función matemática que toma una entrada y produce una salida. La función se activa cuando el resultado calculado alcanza el umbral especificado.\n","![Funcion Activacion](https://drive.google.com/uc?export=view&id=1w3slknVN9VGDmQzHDoPxhRCQZ1xFwmvN)\n","\n"]},{"cell_type":"code","metadata":{"id":"MTR5YNJosuuC"},"source":["#Las capas densas se definen con activación tanh.\n","dense1 = Dense(32, activation='tanh')(input_layer)\n","dense2 = Dense(16, activation='tanh')(dense1)\n","dense3 = Dense(16, activation='tanh')(dense2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykin9QWZsuuE"},"source":["#### Dropout\n","<p style='text-align: justify;'>\n","Múltiples capas ocultas y una gran cantidad de neuronas en cada capa oculta les da a las redes neuronales la capacidad de modelar la no linealidad compleja de las relaciones subyacentes entre los regresores y el objetivo. Sin embargo, las redes neuronales profundas también pueden sobreajustar los datos de validación y dar malos resultados en la validación o el conjunto de pruebas. El dropout se ha utilizado efectivamente para regularizar redes neuronales profundas. En este ejemplo, se agrega una capa de Salida antes de la capa de salida. El dropout establece aleatoriamente p fracción de neuronas de entrada a cero antes de pasar a la siguiente capa. La eliminación aleatoria de entradas actúa esencialmente como un tipo de agrupamiento o metamodelo bagging.  Usamos p = 0.2 para abandonar el 20% de las características de entrada seleccionadas al azar.</p>"]},{"cell_type":"markdown","metadata":{"id":"GukKkLA8suuE"},"source":["<p style='text-align: justify;'>\n","En el aprendizaje automático, la regularización es una forma de evitar el sobreajuste. La regularización reduce el sobreajuste al agregar una penalización a la función de pérdida. Al agregar esta penalización, el modelo se entrena de tal manera que no aprende pesos de conjunto de características interdependientes. Aquellos de ustedes que conocen la Regresión logística pueden estar familiarizados con las penalizaciones L1 (Laplaciana) y L2 (Gaussiana).</p>\n","\n","![Dropout](https://drive.google.com/uc?export=view&id=1WwBQnaNmT2CfkPR439-uR_5pOy-kAluK)\n","\n","\n","El dropout obliga a una red neuronal a aprender características más robustas que son útiles junto con muchos subconjuntos aleatorios diferentes de las otras neuronas."]},{"cell_type":"code","metadata":{"id":"X56KhvNGsuuF"},"source":["dropout_layer = Dropout(0.2)(dense3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wV-AMyQGsuuH"},"source":["# Finalmente, la capa de salida da predicción para la presión de aire del día siguiente.\n","output_layer = Dense(1, activation='linear')(dropout_layer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vah7sG0PsuuJ"},"source":["Las capas de entrada, densa y de salida ahora se empaquetarán dentro de un Modelo, que es una clase envolvente para entrenar y hacer predicciones. El box plot de pm2.5 muestra la presencia de valores atípicos. Por lo tanto, el error absoluto medio (MAE) se usa ya que las desviaciones absolutas sufren menos fluctuaciones en comparación con las desviaciones al cuadrado.\n","\n","Los pesos de la red están optimizados por el algoritmo Adam. Adam representa la estimación del momento adaptativo y ha sido una opción popular para entrenar redes neuronales profundas. A diferencia del descenso de gradiente estocástico, Adam usa diferentes tasas de aprendizaje para cada peso y actualiza por separado lo mismo a medida que avanza el entrenamiento. La tasa de aprendizaje de un peso se actualiza con base en promedios móviles ponderados exponencialmente de los gradientes del peso y los gradientes al cuadrado."]},{"cell_type":"markdown","metadata":{"id":"GgdrHJolsuuJ"},"source":["### Loss Functions\n","<p style='text-align: justify;'>\n","Las máquinas aprenden mediante una función de pérdida. Es un método para evaluar qué tan bien el algoritmo específico modela los datos dados. Si las predicciones se desvían demasiado de los resultados reales, la función de pérdida arrojaría un número muy grande. Gradualmente, con la ayuda de alguna función de optimización, la función de pérdida aprende a reducir el error en la predicción. </p>\n","\n","<p style='text-align: justify;'>\n","No existe una función de pérdida única para todos los algoritmos en el aprendizaje automático. Hay varios factores involucrados en la elección de una función de pérdida para un problema específico, como el tipo de algoritmo de aprendizaje automático elegido, la facilidad de calcular las derivadas y, en cierta medida, el porcentaje de valores atípicos en el conjunto de datos.\n","    </p>\n","\n","<p style='text-align: justify;'>\n","    En términos generales, las funciones de pérdida se pueden clasificar en dos categorías principales según el tipo de tarea de aprendizaje con la que nos estamos ocupando: pérdidas de regresión y pérdidas de clasificación. En la clasificación, estamos tratando de predecir la salida del conjunto de valores categóricos finitos, es decir, dado un gran conjunto de datos de imágenes de dígitos escritos a mano, categorizándolos en uno de 0 a 9 dígitos. La regresión, por otro lado, trata de predecir un valor continuo, por ejemplo, dada la superficie del piso, el número de habitaciones, el tamaño de las habitaciones, predecir el precio de la habitación.</p>\n","    \n","**Regression Losses:**\n","\n","1. Mean Square Error (L2) $MSE = \\frac{\\sum_{y=1}^n(y_i - \\hat{y_i})^2}{n}$\n","\n","Como su nombre indica, el error cuadrático medio se mide como el promedio de la diferencia cuadrática entre las predicciones y las observaciones reales. Solo le preocupa la magnitud promedio del error, independientemente de su dirección. Sin embargo, debido a la cuadratura, las predicciones que están muy lejos de los valores reales se penalizan fuertemente en comparación con las predicciones menos desviadas. Además, MSE tiene buenas propiedades matemáticas que facilitan el cálculo de gradientes.\n","\n","2. Mean Absolute Error (L1) $MAE = \\frac{\\sum_{y=1}^n|y_i - \\hat{y_i}|}{n}$\n","\n","El error absoluto medio, por otro lado, se mide como el promedio de la suma de las diferencias absolutas entre las predicciones y las observaciones reales. Al igual que MSE, esto también mide la magnitud del error sin considerar su dirección. A diferencia de MSE, MAE necesita herramientas más complicadas como la programación lineal para calcular los gradientes. Además, MAE es más robusto para los valores atípicos, ya que no utiliza el cuadrado.\n","\n","3. Mean Bias Error $MBE = \\frac{\\sum_{y=1}^n (y_i - \\hat{y_i})}{n} $\n","\n","**Classification Losses:**\n","\n","1. Cross Entropy Loss = $ -(y_ilog(\\hat(y_i)+(1-y_i)log(1-\\hat{y_i})$\n","\n","Tenga en cuenta que cuando la etiqueta real es 1 (y(i) = 1), la segunda mitad de la función desaparece, mientras que en caso de que la etiqueta real sea 0 (y (i) = 0), la primera mitad se descarta. En resumen, solo estamos multiplicando el registro de la probabilidad pronosticada real para la clase de verdad básica. Un aspecto importante de esto es que la pérdida de entropía cruzada penaliza fuertemente las predicciones que son confiables pero erróneas."]},{"cell_type":"markdown","metadata":{"id":"4q0yLr81suuJ"},"source":["#### Metodos de optimización:\n","\n","<p style='text-align: justify;'>\n","El aprendizaje profundo es un proceso iterativo. Con tantos parámetros para ajustar o métodos para probar, es importante poder entrenar modelos rápidamente, para completar rápidamente el ciclo iterativo. Esto es clave para aumentar la velocidad y la eficiencia de un equipo de aprendizaje automático.\n","De ahí la importancia de los algoritmos de optimización, como el descenso de gradiente estocástico, el descenso de gradiente de lote mínimo, el descenso de gradiente con impulso y el optimizador Adam.</p>\n","<p style='text-align: justify;'>\n","Estos métodos hacen posible que nuestra red neuronal aprenda. Sin embargo, algunos métodos funcionan mejor que otros en términos de velocidad. </p>\n","\n","\n","1. Mini-batch gradient descent: El descenso de gradiente tradicional necesita procesar todos los ejemplos de entrenamiento antes de realizar la primera actualización de los parámetros. En su lugar de eso, considere dividir el conjunto de prueba en conjuntos más pequeños. Cada conjunto pequeño se llama mini lote. Digamos que cada mini lote tiene 64 puntos de entrenamiento. ¡Entonces, podríamos entrenar el algoritmo en un mini lote a la vez y dar un paso una vez que se realice el entrenamiento para cada mini lote!\n","\n","2. Gradient descent with momentum: El descenso de gradiente con momentum implica aplicar un suavizado exponencial al gradiente calculado. Esto acelerará el entrenamiento, porque el algoritmo oscilará menos hacia el mínimo y tomará más pasos hacia el mínimo. Por lo general, se utiliza un suavizado exponencial simple, lo que significa que hay dos hiperparámetros más para ajustar: la tasa de aprendizaje alfa y el parámetro de suavizado beta. Por lo general, este método casi siempre funciona mejor que el descenso de gradiente tradicional, y puede combinarse con el descenso de gradiente de mini lotes.\n","\n","3. Adam significa: estimación adaptativa del momento. El método suaviza el gradiente, al igual que el momentum, pero utiliza un enfoque diferente. Se introducen 4 hyperparámetros. $\\alpha, \\beta?1 (0.9), \\beta_2 (0.999), \\epsilon$\n","\n","\n","$$S_{dw} = \\beta_2S_{dw}+(1-\\beta_2)dw^2 $$\n","<br>\n","$$S_{db} = \\beta_2S_{db}+(1-\\beta_2)db^2 $$\n","\n","Entonces\n","\n","$$ w:= w -\\alpha\\frac{dw}{\\sqrt{S_{dw}+ \\epsilon}}$$\n","<br>\n","$$ b:= b -\\alpha\\frac{db}{\\sqrt{S_{db}+ \\epsilon}}$$\n","\n","Adam en Pseudocodigo\n","![Adam](https://drive.google.com/uc?export=view&id=1KtPjaukUkuztA3HsjnDj_5NbxglXsWFO)\n"]},{"cell_type":"markdown","metadata":{"id":"6YjpPf7RsuuK"},"source":["#### Backpropagation\n","\n","<p style='text-align: justify;'>\n","En el aprendizaje automático, la retropropagación es un algoritmo ampliamente utilizado en el entrenamiento de redes neuronales  para el aprendizaje supervisado. Las generalizaciones de la retropropagación existen para otras redes neuronales artificiales (ANN), y para funciones en general, una clase de algoritmos a los que se hace referencia genéricamente como \"retropropagación\". Al ajustar una red neuronal, la propagación hacia atrás calcula el gradiente de la función de pérdida con respecto a los pesos de la red para un solo ejemplo de entrada-salida, y lo hace de manera eficiente, a diferencia de un cálculo directo ingenuo del gradiente con respecto a cada peso individualmente. Esta eficiencia hace posible el uso de métodos de gradiente para entrenar redes multicapa, actualizar pesos para minimizar pérdidas; Descenso de gradiente, o variantes como el descenso de gradiente estocástico, se usan comúnmente. El algoritmo de retropropagación funciona calculando el gradiente de la función de pérdida con respecto a cada peso por la regla de la cadena, calculando el gradiente una capa a la vez, iterando hacia atrás desde la última capa para evitar cálculos redundantes de términos intermedios en la regla de la cadena; Este es un ejemplo de programación dinámica.</p>\n","\n","![Backpropagation](https://drive.google.com/uc?export=view&id=1WZ7CuIk9B88wFtWAcEMsU8OleDVn9RgW)\n","\n"]},{"cell_type":"code","metadata":{"id":"0xGR4tZusuuK"},"source":["ts_model = Model(inputs=input_layer, outputs=output_layer)\n","ts_model.compile(loss='mean_absolute_error', optimizer='adam')\n","ts_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wOeqaasisuuN"},"source":["El modelo se entrena llamando a la función de ajuste en el objeto modelo y pasando el X_train y el y_train. El entrenamiento se realiza para un número predefinido de epochs. Además, batch_size define el número de muestras del conjunto de entrenamiento que se utilizarán para una instancia de propagación inversa. El conjunto de datos de validación también se pasa para evaluar el modelo después de que se complete cada epochs. Un objeto ModelCheckpoint rastrea la función de pérdida en el conjunto de validación y guarda el modelo para el epochs, en la que la función de pérdida ha sido mínima."]},{"cell_type":"code","metadata":{"id":"PUsBwZ8ksuuN"},"source":["path = '/content/drive/My Drive/Cursos/Diplomado/Kafka/PrediccionPm2.5-MLP/models'\n","save_weights_at = os.path.join(path, 'PRSA_data_PM2.5_MLP_weights.{epoch:02d}-{val_loss:.4f}.hdf5')\n","save_best = ModelCheckpoint(save_weights_at, monitor='val_loss', verbose=0,\n","                            save_best_only=True, save_weights_only=False, mode='min',\n","                            period=1)\n","ts_model.fit(x=X_train, y=y_train, batch_size=16, epochs=30,\n","             verbose=1, callbacks=[save_best], validation_data=(X_val, y_val),\n","             shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B6XVcHlGI4FD"},"source":["## <font color='green'>**Actividad 2**</font>\n","\n","Proponga, construya y entrene su propia red neuronal. (40 Minutos)"]},{"cell_type":"markdown","metadata":{"id":"P3LXjj_tJEGo"},"source":["<font color='green'>**Fin Actividad 2**</font>"]},{"cell_type":"markdown","metadata":{"id":"Jusywo1EJbTF"},"source":["## <font color='green'>**Actividad 3**</font>\n","\n","Evalue el resultado del modelo (30 minutos). Utilice\n","1. Mae\n","2. R2\n","3. Grafico de linea."]},{"cell_type":"markdown","metadata":{"id":"Mcuohs-BsuuP"},"source":["Se hacen predicciones para el pm2.5 del modelo mejor guardado. Las predicciones del modelo, que están en el pm2.5 escalado, se transforman inversamente para obtener predicciones del pm2.5 original."]},{"cell_type":"markdown","metadata":{"id":"wP9hmk6JJrZj"},"source":["<font color='green'>**Fin Actividad 3**</font>"]},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?export=view&id=1DNuGbS1i-9it4Nyr3ZMncQz9cRhs2eJr\" width=\"100\" align=\"left\" title=\"Runa-perth\">\n","<br clear=\"left\">\n","\n","## <font color='green'>**Metodos de series de tiempo con deep learning.**</font>\n","\n","Las redes neuronales se utilizan en una amplia variedad de aplicaciones relacionadas con series temporales, debido a su capacidad para aprender patrones y relaciones a partir de datos secuenciales. Las series temporales son secuencias de datos medidos en intervalos de tiempo consecutivos, y se utilizan en muchos campos, incluyendo finanzas, medicina, ingeniería y ciencias sociales.\n","\n","Aquí hay un resumen de las principales aplicaciones de las redes neuronales en series temporales, así como los conceptos clave utilizados:\n","\n","Predicción de series temporales: Las redes neuronales se utilizan para predecir futuros puntos en una serie temporal basándose en datos históricos. Esto es útil en áreas como la previsión del mercado de valores, la planificación de la demanda y la predicción del tiempo.\n","\n","Clasificación de series temporales: Las redes neuronales pueden aprender patrones en series temporales y clasificarlas en diferentes categorías. Por ejemplo, en el campo de la medicina, las series temporales de señales de electrocardiograma (ECG) pueden ser clasificadas como normales o anormales.\n","\n","Anomalía en la detección de series temporales: Las redes neuronales se utilizan para detectar puntos anómalos en una serie temporal. Esto es útil en áreas como el monitoreo de maquinaria industrial para detectar fallos antes de que ocurran.\n","\n","Conceptos clave en el uso de redes neuronales para series temporales:\n","\n","Redes neuronales recurrentes (RNN): Son un tipo de red neuronal que tiene conexiones que se retroalimentan, lo que les permite mantener un estado interno y recordar información de pasos anteriores. Son especialmente adecuadas para el análisis de series temporales.\n","\n","LSTM (Long Short-Term Memory): Es un tipo de RNN que utiliza celdas de memoria para mantener un estado a lo largo de largas secuencias, lo que les permite aprender patrones a largo plazo en series temporales.\n","\n","GRU (Gated Recurrent Unit): Es otro tipo de RNN que utiliza compuertas para regular el flujo de información, similar a las LSTM pero con una estructura más simple.\n","\n","Transformadores: Son una arquitectura de red neuronal que utiliza mecanismos de atención para capturar relaciones en secuencias de datos. Se utilizan para modelar series temporales con patrones complejos y a largo plazo.\n","\n","Ventanas de tiempo: Al trabajar con series temporales, a menudo se dividen en ventanas de tiempo o subsecuencias para entrenar a la red neuronal en patrones más cortos.\n","\n","Descomposición de series temporales: Se puede descomponer una serie temporal en componentes como tendencia, estacionalidad y ruido, lo que facilita el análisis y la predicción.\n","\n","Embeddings temporales: A veces, se utilizan técnicas de incrustación para convertir series temporales en representaciones de baja dimensión que pueden ser más fácilmente analizadas por redes neuronales.\n","\n","En resumen, las redes neuronales son herramientas poderosas para el análisis de series temporales, y se utilizan en una amplia gama de aplicaciones para predecir, clasificar y detectar anomalías en datos secuenciales."],"metadata":{"id":"tykdEhZVHaBb"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?export=view&id=1Igtn9UXg6NGeRWsqh4hefQUjV0hmzlBv\" width=\"100\" align=\"left\" title=\"Runa-perth\">\n","<br clear=\"left\">\n","\n","## <font color='red'>**Otras Arquitecturas de redes para series de datos.**</font>\n","\n","### Red LSTM (Long Short-Term Memory):\n","\n","Las LSTM son un tipo de redes neuronales recurrentes (RNN) diseñadas específicamente para evitar el problema de la desaparición del gradiente. Son esenciales para tareas de secuencia debido a su capacidad para recordar información a largo plazo. Aquí hay un breve resumen:\n","\n","1. Memoria a Largo Plazo: A diferencia de las redes neuronales tradicionales, las LSTM tienen una estructura de memoria que les ayuda a recordar patrones o secuencias durante largos períodos, lo que las hace ideales para tareas relacionadas con series temporales y procesamiento del lenguaje natural.\n","\n","2. Unidades de Puerta: Una característica clave de las LSTM son sus \"puertas\" (gate units). Estas puertas determinan qué información debe ser almacenada o descartada en la memoria celular. Hay tres tipos principales de puertas en una LSTM:\n","\n","  a. Puerta de Entrada (Input Gate): Decide cuánta información nueva se almacenará en la memoria celular.\n","\n","  b. Puerta de Olvido (Forget Gate): Decide cuánta información de la memoria celular actual se descartará.\n","  \n","  c. Puerta de Salida (Output Gate): Basándose en la memoria celular, decide cuál será el próximo estado oculto.\n","\n","3. Flexibilidad en Secuencias: Las LSTM pueden manejar secuencias de entrada de diferentes longitudes sin necesidad de especificar la longitud de la secuencia con antelación.\n","\n","4. Aplicaciones: Debido a su capacidad para recordar a largo plazo, las LSTM se utilizan en una variedad de aplicaciones, como traducción automática, generación de texto, análisis de sentimiento, series temporales, entre otros.\n","\n","5. Variantes: Hay diversas variantes y extensiones de las LSTM, como las GRU (Gated Recurrent Units), que simplifican la arquitectura de las LSTM pero retienen la mayoría de sus beneficios."],"metadata":{"id":"Ghb6EqS0M2cG"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Generar datos\n","x = np.linspace(0, 50, 1000)\n","y = np.sin(x)\n","\n","plt.plot(x, y)\n","plt.title(\"Serie de tiempo sinusoidal\")\n","plt.show()\n"],"metadata":{"id":"BgKRZdCbM8tA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataset(data, steps):\n","    X, Y = [], []\n","    for i in range(len(data)-steps-1):\n","        X.append(data[i:(i+steps)])\n","        Y.append(data[i + steps])\n","    return np.array(X), np.array(Y)\n","\n","steps = 10\n","X, Y = create_dataset(y, steps)\n","\n","# Reshape para [muestras, pasos de tiempo, características]\n","X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n"],"metadata":{"id":"pTyLmwLkM-_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","\n","model = Sequential()\n","model.add(LSTM(30, activation='relu', input_shape=(steps, 1)))\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mse')\n"],"metadata":{"id":"QR5L3klHNBHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(X, Y, epochs=50, verbose=1)\n"],"metadata":{"id":"DDL6KZ2XNDk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(X)\n","\n","plt.figure(figsize=(15,6))\n","plt.plot(y, label='Verdadero')\n","plt.plot(np.arange(steps, 1000-1), y_pred, label='Predicho', alpha=0.7)\n","plt.title(\"Verdadero vs. Predicho\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"akWSOEleNMCl"},"execution_count":null,"outputs":[]}]}