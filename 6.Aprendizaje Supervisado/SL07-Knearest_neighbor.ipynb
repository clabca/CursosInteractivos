{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qOvxOeJduU-z"},"source":["# **Aprendizaje supervisado**\n","# SL07. k-Nearest Neighbor"]},{"cell_type":"markdown","metadata":{"id":"J03PQMmkxCzA"},"source":["## <font color='blue'>**k-Nearest Neighbor**</font>\n","\n","K-Nearest-Neighbor es un algoritmo basado en instancia de tipo supervisado de Machine Learning. Puede usarse para clasificar nuevas muestras (valores discretos) o para predecir (regresión, valores continuos). Al ser un método sencillo, es ideal para introducirse en el mundo del  Aprendizaje Automático. Sirve esencialmente para clasificar valores buscando los puntos de datos “más similares” (por cercanía) aprendidos en la etapa de entrenamiento y haciendo conjeturas de nuevos puntos basado en esa clasificación."]},{"cell_type":"markdown","metadata":{"id":"rqzrledUxNQ8"},"source":["## ¿Qué es el algoritmo k-Nearest Neighbor?\n","\n","Es un método que simplemente busca en las observaciones más cercanas a la que se está tratando de predecir y clasifica el punto de interés basado en la mayoría de datos que le rodean. Como dijimos antes, es un algoritmo:\n","\n","**Supervisado**: esto -brevemente- quiere decir que tenemos etiquetado nuestro conjunto de datos de entrenamiento, con la clase o resultado esperado dada “una fila” de datos.\n","\n","**Basado en Instancia**: Esto quiere decir que nuestro algoritmo no aprende explícitamente un modelo (como por ejemplo en Regresión Logística o árboles de decisión). En cambio memoriza las instancias de entrenamiento que son usadas como “base de conocimiento” para la fase de predicción.\n"]},{"cell_type":"markdown","metadata":{"id":"xDHoLtzoxXCT"},"source":["## ¿Dónde se aplica k-Nearest Neighbor?\n","\n","Aunque sencillo, se utiliza en la resolución de multitud de problemas, como en sistemas de recomendación, búsqueda semántica y detección de anomalías.\n","## Pros y contras\n","\n","Como pros tiene sobre todo que es sencillo de aprender e implementar. Tiene como contras que utiliza todo el dataset para entrenar “cada punto” y por eso requiere de uso de mucha memoria y recursos de procesamiento (CPU). Por estas razones kNN tiende a funcionar mejor en datasets pequeños y sin una cantidad enorme de features (las columnas)."]},{"cell_type":"markdown","metadata":{"id":"hM7quXloxgg-"},"source":["## ¿Cómo funciona kNN?\n","\n","1. Calcular la distancia entre el item a clasificar y el resto de items del dataset de entrenamiento.\n","2. Seleccionar los “k” elementos más cercanos (con menor distancia, según la función que se use)\n","3. Realizar una “votación de mayoría” entre los k puntos: los de una clase/etiqueta que <<dominen>> decidirán su clasificación final.\n","\n","Teniendo en cuenta el punto 3, veremos que para decidir la clase de un punto es muy importante el valor de k, pues este terminará casi por definir a qué grupo pertenecerán los puntos, sobre todo en las “fronteras” entre grupos. Por ejemplo -y a priori- yo elegiría valores impares de k para desempatar (si las features que utilizamos son pares). No será lo mismo tomar para decidir 3 valores que 13. Esto no quiere decir que necesariamente tomar más puntos implique mejorar la precisión. Lo que es seguro es que cuantos más “puntos k”, más tardará nuestro algoritmo en procesar y darnos respuesta.\n","\n","Las formas más populares de “medir la cercanía” entre puntos son la distancia Euclidiana (la “de siempre”) o la Cosine Similarity (mide el ángulo de  los vectores, cuanto menores, serán similares). Recordemos que este algoritmo -y prácticamente todos en ML- funcionan mejor con varias características de las que tomemos datos (las columnas de nuestro dataset). Lo que entendemos como “distancia” en la vida real, quedará abstracto a muchas dimensiones que no podemos “visualizar” fácilmente (como por ejemplo en un mapa).\n","\n","![Imagen](https://drive.google.com/uc?id=1cKo1M5xC5fYwwiOJbF4D2cR8ThUBtyoq)"]},{"cell_type":"markdown","metadata":{"id":"U_SVUytwz6sx"},"source":["## Un ejemplo"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:07.018425Z","start_time":"2018-07-08T21:06:05.294010Z"},"id":"dYbJUxKhuU-4"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import matplotlib.patches as mpatches\n","import seaborn as sb\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (16, 9)\n","plt.style.use('ggplot')\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTczkzpcuU-4"},"source":["# Leemos nuestro archivo de entrada"]},{"cell_type":"code","metadata":{"id":"KFs001wcbtmS"},"source":["from google.colab import files\n","\n","uploaded = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:07.085378Z","start_time":"2018-07-08T21:06:07.021056Z"},"id":"pW6M0GbBuU-6"},"source":["dataframe = pd.read_csv(r\"reviews_sentiment.csv\",sep=';')\n","dataframe.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:07.122278Z","start_time":"2018-07-08T21:06:07.088645Z"},"id":"pa-wrp5quU-8"},"source":["dataframe.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EhbGB606uU-8"},"source":["## Rápidas visualizaciones"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:07.592242Z","start_time":"2018-07-08T21:06:07.127692Z"},"id":"SB5iwjTAuU-8"},"source":["dataframe.hist()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:07.603298Z","start_time":"2018-07-08T21:06:07.595168Z"},"id":"VLZ3Ky8uuU-9"},"source":["print(dataframe.groupby('Star Rating').size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:07.821277Z","start_time":"2018-07-08T21:06:07.606864Z"},"scrolled":true,"id":"NFNvUj3yuU--"},"source":["sb.factorplot('Star Rating',data=dataframe,kind=\"count\", aspect=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:08.264250Z","start_time":"2018-07-08T21:06:07.824002Z"},"id":"agMWoQuZuU--"},"source":["sb.factorplot('wordcount',data=dataframe,kind=\"count\", aspect=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3wh6_8FYuU-_"},"source":["## Preparamos el dataset"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:08.274906Z","start_time":"2018-07-08T21:06:08.267067Z"},"id":"gI47_VjeuU_A"},"source":["X = dataframe[['wordcount','sentimentValue']].values\n","y = dataframe['Star Rating'].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-fma4RzVuU_A"},"source":["## Creamos el Modelo"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:08.298007Z","start_time":"2018-07-08T21:06:08.281409Z"},"id":"CfnTXd-PuU_B"},"source":["n_neighbors = 7\n","\n","knn = KNeighborsClassifier(n_neighbors)\n","knn.fit(X_train, y_train)\n","print('Accuracy of K-NN classifier on training set: {:.2f}'\n","     .format(knn.score(X_train, y_train)))\n","print('Accuracy of K-NN classifier on test set: {:.2f}'\n","     .format(knn.score(X_test, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L9dT4PSQuU_C"},"source":["## Resultados obtenidos"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:08.318080Z","start_time":"2018-07-08T21:06:08.303739Z"},"id":"HHp6AhYXuU_C"},"source":["pred = knn.predict(X_test)\n","print(confusion_matrix(y_test, pred))\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lmqOd656uU_C"},"source":["# Gráfica de la Clasificación Obtenida"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:38.684163Z","start_time":"2018-07-08T21:06:08.324560Z"},"code_folding":[],"id":"msYQZ8j4uU_D"},"source":["h = .02  # step size in the mesh\n","\n","# Create color maps\n","cmap_light = ListedColormap(['#FFAAAA', '#ffcc99', '#ffffb3','#b3ffff','#c2f0c2'])\n","cmap_bold = ListedColormap(['#FF0000', '#ff9933','#FFFF00','#00ffff','#00FF00'])\n","\n","# we create an instance of Neighbours Classifier and fit the data.\n","clf = KNeighborsClassifier(n_neighbors, weights='distance')\n","clf.fit(X, y)\n","\n","# Plot the decision boundary. For that, we will assign a color to each\n","# point in the mesh [x_min, x_max]x[y_min, y_max].\n","x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n","                         np.arange(y_min, y_max, h))\n","Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","\n","# Put the result into a color plot\n","Z = Z.reshape(xx.shape)\n","plt.figure()\n","plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n","\n","# Plot also the training points\n","plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n","                edgecolor='k', s=20)\n","plt.xlim(xx.min(), xx.max())\n","plt.ylim(yy.min(), yy.max())\n","\n","patch0 = mpatches.Patch(color='#FF0000', label='1')\n","patch1 = mpatches.Patch(color='#ff9933', label='2')\n","patch2 = mpatches.Patch(color='#FFFF00', label='3')\n","patch3 = mpatches.Patch(color='#00ffff', label='4')\n","patch4 = mpatches.Patch(color='#00FF00', label='5')\n","plt.legend(handles=[patch0, patch1, patch2, patch3,patch4])\n","\n","\n","plt.title(\"5-Class classification (k = %i, weights = '%s')\"\n","              % (n_neighbors, 'distance'))\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_6L2FKuuU_D"},"source":["## Cómo obtener el mejor valor de k"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:38.869436Z","start_time":"2018-07-08T21:06:38.687690Z"},"id":"5vbSMmMAuU_D"},"source":["k_range = range(1, 20)\n","scores = []\n","for k in k_range:\n","    knn = KNeighborsClassifier(n_neighbors = k)\n","    knn.fit(X_train, y_train)\n","    scores.append(knn.score(X_test, y_test))\n","plt.figure()\n","plt.xlabel('k')\n","plt.ylabel('accuracy')\n","plt.scatter(k_range, scores)\n","plt.xticks([0,5,10,15,20])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E2cZLrxXuU_E"},"source":["# Predicciones"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:38.890532Z","start_time":"2018-07-08T21:06:38.879285Z"},"id":"fh4cv2vRuU_E"},"source":["print(clf.predict([[5, 1.0]]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-07-08T21:06:38.903309Z","start_time":"2018-07-08T21:06:38.894227Z"},"id":"by4t_bxguU_E"},"source":["print(clf.predict_proba([[20, 0.0]]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-DbGLbRuU_F"},"source":["## <font color='green'>Actividad 1</font>\n","\n","Construiremos un modelo kNN utilizando el data set *breast cancer*. A continuación de entregan los pasos principales para construir su modelo."]},{"cell_type":"code","metadata":{"id":"KEgxEq_QuU_F"},"source":["from sklearn.datasets import load_breast_cancer\n","data = load_breast_cancer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZ2SU_G5uU_F"},"source":["X=data.data\n","y=data.target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zxhnZ0NZuU_F"},"source":["Separe en entrenamiento y test."]},{"cell_type":"code","metadata":{"id":"tUMFXpCquU_G"},"source":["# Tú codigo aquí"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w5DWW0OB1p1s"},"source":["Encuentre el mejor valor de k que maximice accuracy."]},{"cell_type":"code","metadata":{"id":"KuEc0O0U3p2t"},"source":["# Tú codigo aquí"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZKzk9ez3rrz"},"source":["Genere un reporte de clasificacion (classification_report)"]},{"cell_type":"code","metadata":{"id":"v17-PtjQ34Fv"},"source":["# Tú codigo aquí"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SCtT7PZt32Fe"},"source":["Realice un 5 fold crossvalidation de 20 experimentos. Reporte el promedio y desviacion estandar de accuracy."]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn import datasets, metrics\n","import numpy as np\n","\n","\n","# Tú codigo aquí\n","\n","import numpy as np\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Cargar el conjunto de datos\n","data = load_breast_cancer()\n","X = data.data\n","y = data.target\n","\n","# Normalizar los datos\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Parámetro k óptimo obtenido anteriormente\n","best_k = 9\n","\n","# Crear el clasificador kNN con el mejor valor de k\n","knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n","\n","# Realizar 20 experimentos de 5-fold cross-validation y almacenar las precisones en una lista\n","accuracies = []\n","for _ in range(20):\n","    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","    accuracy_scores = cross_val_score(knn_classifier, X, y, cv=kfold, scoring='accuracy')\n","    accuracies.extend(accuracy_scores)\n","\n","# Calcular el promedio y la desviación estándar de la precisión\n","mean_accuracy = np.mean(accuracies)\n","std_accuracy = np.std(accuracies)\n","\n","print(f'Promedio de accuracy: {mean_accuracy:.4f}')\n","print(f'Desviación estándar de accuracy: {std_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWvOsZ_NUiDK","executionInfo":{"status":"ok","timestamp":1705090646605,"user_tz":180,"elapsed":6712,"user":{"displayName":"Carol Diaz","userId":"03863088177087652040"}},"outputId":"a3e6aa69-a253-44a1-d6ce-c3bd9c98c182"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Promedio de accuracy: 0.9649\n","Desviación estándar de accuracy: 0.0124\n"]}]},{"cell_type":"markdown","metadata":{"id":"bKZcBbq00eWq"},"source":["<font color='green'>Fin Actividad 1</font>"]},{"cell_type":"markdown","source":[],"metadata":{"id":"_P6MiFdMUqhs"}}]}