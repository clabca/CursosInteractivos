{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3.7.7 64-bit ('MLprojects': conda)","language":"python","name":"python37764bitmlprojectsconda9e66019a9ab047499c0882be49df755b"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"toc-autonumbering":true,"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"oTjsMZH0GUK-"},"source":["# **Aprendizaje supervisado**\n","# SL14. Curvas de análisis para modelos de clasificación\n"]},{"cell_type":"code","metadata":{"id":"QylNgTeVGULD"},"source":["import pandas as pd\n","import numpy as np\n","import warnings\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB\n","\n","import matplotlib.pyplot as plt\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIs_6C_1JGc0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d65m43BjGULD"},"source":["## <font color='blue'>**Modelo de Predicción de Supervivientes en Titanic.**</font>"]},{"cell_type":"code","metadata":{"id":"X4fmMgFVGULE"},"source":["df = pd.read_csv('/content/drive/MyDrive/UDD/Modulo 5- Aprendizaje Supervisado/VGroup/files/titanic.csv', index_col = 0)\n","df[['Pclass', 'Sex','Embarked']] = df[['Pclass', 'Sex','Embarked']].astype('category')\n","df['Age'] = df.Age.fillna(df.Age.mean())\n","df.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTBpr2seGULF"},"source":["X = df[['Pclass', 'Sex','Age','Parch','Fare','Embarked']]\n","y = df.Survived\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-33ZsLXmOl0"},"source":["pip install category_encoders"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mK1pvLT8GULF"},"source":["from category_encoders import OneHotEncoder\n","from sklearn.preprocessing import StandardScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"owNUsWr3mnul"},"source":["ohe = OneHotEncoder(use_cat_names = True)\n","X_train_enc = ohe.fit_transform(X_train)\n","X_test_enc = ohe.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Ub0kyYVnFYv"},"source":["sc = StandardScaler()\n","X_train_sc = sc.fit_transform(X_train_enc)\n","X_test_sc = sc.transform(X_test_enc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"03kfEY6hGULF"},"source":["lr = LogisticRegression(random_state = 123)\n","lr.fit(X_train_sc, y_train)\n","y_pred = lr.predict(X_test_sc)\n","y_pred_train = lr.predict(X_test_sc)\n","y_proba = lr.predict_proba(X_test_sc)\n","\n","print('Score Train:', lr.score(X_train_sc, y_train))\n","print('Score Test:', lr.score(X_test_sc, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPn7I0PUGULG"},"source":["lr.coef_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fb09r0IGULG"},"source":["lr.intercept_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-u6ikgXoTn9j"},"source":["pip install scikit-plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xkQOdI2GULI"},"source":["from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from scikitplot.metrics import plot_confusion_matrix, plot_roc, plot_cumulative_gain, plot_precision_recall, plot_lift_curve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nSa2gw3GULI"},"source":["confusion_matrix(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibC812yIGULI"},"source":["plot_confusion_matrix(y_test, y_pred, title = 'Matriz de Confusión',text_fontsize = 'large', title_fontsize = 'large', figsize = (10,8))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CymuPzrRGULJ"},"source":["print(classification_report(y_test, y_pred, digits = 4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tMGdxwdFndS_"},"source":["## <font color='blue'>**¿Cómo Elegir el Mejor Modelo?**</font>"]},{"cell_type":"markdown","metadata":{"id":"Pld-xzIMGULM"},"source":["## Curva Precision-Recall\n","\n","Esta curva presenta el trade-off Precision-Recall de todos los puntos de corte. De esa manera se puede escoger el punto de corte que optimice la métrica que se quiere escoger o utilizar el área bajo la curva como una métrica de medida.\n","\n","<img src='https://drive.google.com/uc?export=view&id=1ZHKnkQ5Hm-y2dnvqW2mYbAu1L-7-AH0o' width=\"600\" align=\"center\" style=\"margin-right: 20px\">"]},{"cell_type":"code","metadata":{"id":"Em-WRLEsGULM"},"source":["plot_precision_recall(y_test, y_proba, title = 'Curva Precision-Recall', plot_micro = False, classes_to_plot = [0,1], figsize = (10,8))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nrTLWGiGULM"},"source":["y.value_counts() #Debido a que Titanic es un dataset relativamente desbalanceado, podría ser una métrica más honesta"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"22oDudHRX3hC"},"source":["La utilización de esta curva es particularmente útil cuando se trabaja con clases desbalanceadas. Normalmente se utiliza el área bajo la curva (AUC) como una medida, donde 1 representa un modelo perfecto."]},{"cell_type":"markdown","metadata":{"id":"SePaDg7EGULM"},"source":["## Curva Receiver Operating Characteristic - ROC\n","\n","Esta curva representa el trade-off entre el recall (también llamado sensibilidad) y 1 - Especifidad, donde la Especifidad representa el Recall de la otra clase (para problemas binarios). Al igual que la curva representa este trade-off para todos los puntos de corte posible.\n","\n","Adicionalmente existe una interpretación alternativa, en la cual la curva ROC representa la probabilidad de que un punto de la clase positiva tenga una mayor probabilidad que un punto de la clase negativa. Es decir, la probabilidad de que el modelo pueda ordenar las predicciones correctamente por probabilidad.\n","\n","<img src='https://drive.google.com/uc?export=view&id=1He2TUyM75fd6ja-aSQq3nB04Y5FV6FEN' width=\"600\" align=\"center\" style=\"margin-right: 20px\">"]},{"cell_type":"code","metadata":{"id":"96aJ0hGEGULM"},"source":["plot_roc(y_test, y_proba, plot_micro = False, plot_macro = False, title = 'Curva ROC', figsize = (10,8))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7MNXXKgXGULN"},"source":["## Curva Ganancia\n","\n","La curva de Ganancia corresponde a una curva que mide qué porcentaje de la data es necesario para encontrar un cierto porcentaje de la clase requerida.\n","\n","<img src='https://drive.google.com/uc?export=view&id=1ktbS930bK68Pb6t5Qw3HF1M0K8Am672C' width=\"600\" align=\"center\" style=\"margin-right: 20px\">\n","\n","Esta métrica suele ser una métrica muy importante en marketing en donde se puede garantizar un cierto porcentaje de acierto si es que se contacta una cierta muestra con mayor probabilidad de la población a predecir."]},{"cell_type":"code","metadata":{"id":"JbZD-pNkGULN"},"source":["plot_cumulative_gain(y_test, y_proba, title = 'Curva de Ganancia', figsize = (10,8))\n","plt.show()"],"execution_count":null,"outputs":[]}]}